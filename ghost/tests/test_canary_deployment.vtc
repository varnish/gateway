varnishtest "canary deployment with weighted traffic splitting"

# Test that weighted traffic splitting works correctly for canary deployments
# Simulates 90% traffic to stable backend and 10% to canary backend

server s_stable_1 {
    rxreq
    expect req.http.host == "app.example.com"
    txresp -status 200 -body "stable-v1"
} -start

server s_stable_2 {
    rxreq
    expect req.http.host == "app.example.com"
    txresp -status 200 -body "stable-v1"
} -start

server s_canary_1 {
    rxreq
    expect req.http.host == "app.example.com"
    txresp -status 200 -body "canary-v2"
} -start

server s_canary_2 {
    rxreq
    expect req.http.host == "app.example.com"
    txresp -status 200 -body "canary-v2"
} -start

shell {
    cat > ${tmpdir}/ghost.json <<EOF
{
  "version": 2,
  "vhosts": {
    "app.example.com": {
      "routes": [
        {
          "path_match": {
            "type": "PathPrefix",
            "value": "/"
          },
          "backends": [
            {"address": "${s_stable_1_addr}", "port": ${s_stable_1_port}, "weight": 90},
            {"address": "${s_stable_2_addr}", "port": ${s_stable_2_port}, "weight": 90},
            {"address": "${s_canary_1_addr}", "port": ${s_canary_1_port}, "weight": 10},
            {"address": "${s_canary_2_addr}", "port": ${s_canary_2_port}, "weight": 10}
          ],
          "priority": 100
        }
      ]
    }
  }
}
EOF
}

varnish v1 -arg "-p thread_pool_stack=160k" -vcl {
    import ghost from "${vmod}";

    backend dummy none;

    sub vcl_init {
        ghost.init("${tmpdir}/ghost.json");
        new router = ghost.ghost_backend();
    }

    sub vcl_recv {
        if (req.url == "/.varnish-ghost/reload" && (client.ip == "127.0.0.1" || client.ip == "::1")) {
            if (router.reload()) {
                return (synth(200, "OK"));
            } else {
                return (synth(500, "Reload failed"));
            }
        }
    }

    sub vcl_backend_fetch {
        set bereq.backend = router.backend();
    }
} -start

# Trigger initial reload
client creload {
    txreq -url "/.varnish-ghost/reload"
    rxresp
    expect resp.status == 200
} -run

# Make sample requests to verify both stable and canary backends are accessible
# With 90/10 weight split and 4 backends (2 stable, 2 canary), we expect:
# - Stable backends (weight 90 each) = total weight 180
# - Canary backends (weight 10 each) = total weight 20
# - Total weight = 200
# - Stable probability = 180/200 = 90%
# - Canary probability = 20/200 = 10%

client c1 {
    txreq -hdr "Host: app.example.com" -url "/"
    rxresp
    expect resp.status == 200
    # Response will be either "stable-v1" or "canary-v2"
} -repeat 100

# Verify the vhost director is properly registered
varnish v1 -cliok "backend.list"
varnish v1 -cliexpect "ghost.app.example.com" "backend.list"

# Verify detailed backend info shows the director
varnish v1 -cliok "backend.list -p"
varnish v1 -cliexpect "Backend: ghost.app.example.com" "backend.list -p"
varnish v1 -cliexpect "Routes:" "backend.list -p"
varnish v1 -cliexpect "Health: healthy" "backend.list -p"
